{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLIP (01) Practical Data Science\n",
    "\n",
    "---\n",
    "Team Director: Shaoni Wang | snwang@tulip.academy<br />\n",
    "\n",
    "TULIP Academy <br />\n",
    "http://www.tulip.academy\n",
    "\n",
    "---\n",
    "\n",
    "## Session 40 Classifying and Calculating "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Sections\n",
    "\n",
    "\n",
    "<p>&#8226; <a href=\"#given\">Given information</a><br>\n",
    "&#8226; <a href=\"#classify_rand\">Classifying some random example data</a><br>\n",
    "&#8226; <a href=\"#chern_err\">Calculating the Chernoff theoretical bounds for P(error)</a><br>\n",
    "&#8226; <a href=\"#emp_err\">Calculating the empirical error rate</a><br>\n",
    "\n",
    "  \n",
    "\n",
    "  \n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given information:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[<a href=\"#sections\">back to top</a>] <br>\n",
    "\n",
    "<br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "#### model: continuous univariate normal (Gaussian) model for the class-conditional densities\n",
    "\n",
    "\n",
    "$ p(\\vec{x} | \\omega_j) \\sim N(\\vec{\\mu}|\\Sigma) $ \n",
    "\n",
    "$ p(\\vec{x} | \\omega_j) \\sim \\frac{1}{(2\\pi)^{d/2} |\\Sigma|^{1/2}} \\exp{ \\bigg[-\\frac{1}{2} (\\vec{x}-\\vec{\\mu})^t \\Sigma^{-1}(\\vec{x}-\\vec{\\mu}) \\bigg] } $\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Prior probabilities:\n",
    "\n",
    "$ P(\\omega_1) = P(\\omega_2) = 0.5 $\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The samples are of 2-dimensional feature vectors:\n",
    "\n",
    "$\\vec{x} = \\bigg[ \n",
    "\\begin{array}{c}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "\\end{array} \\bigg]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Means of the sample distributions for 2-dimensional features:\n",
    "\n",
    "$\\vec{\\mu}_{\\,1} = \\bigg[ \n",
    "\\begin{array}{c}\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "\\end{array} \\bigg]$,\n",
    "$\\; \\vec{\\mu}_{\\,2} = \\bigg[ \n",
    "\\begin{array}{c}\n",
    "1 \\\\\n",
    "1 \\\\\n",
    "\\end{array} \\bigg]$\n",
    "\n",
    "#### Covariance matrices for the statistically independend and identically distributed ('i.i.d') features: \n",
    "\n",
    "$\\Sigma_i = \\bigg[ \n",
    "\\begin{array}{cc}\n",
    "\\sigma_{11}^2 & \\sigma_{12}^2\\\\\n",
    "\\sigma_{21}^2 & \\sigma_{22}^2 \\\\\n",
    "\\end{array} \\bigg], \\; \n",
    "\\Sigma_1 = \\Sigma_2 = I = \\bigg[ \n",
    "\\begin{array}{cc}\n",
    "1 & 0\\\\\n",
    "0 & 1 \\\\\n",
    "\\end{array} \\bigg], \\;$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class conditional probabilities:\n",
    "\n",
    "$ p(\\vec{x}\\;|\\;\\omega_1) \\sim N \\bigg( \\vec{\\mu_1} = \\;  \\bigg[ \n",
    "\\begin{array}{c}\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "\\end{array} \\bigg], \\Sigma = I \\bigg) $\n",
    "\n",
    "$ p(\\vec{x}\\;|\\;\\omega_2) \\sim N \\bigg( \\vec{\\mu_2} = \\;  \\bigg[ \n",
    "\\begin{array}{c}\n",
    "1 \\\\\n",
    "1 \\\\\n",
    "\\end{array} \\bigg], \\Sigma = I \\bigg) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"deriving_db\"></a>\n",
    "<br></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Classifying some random example data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<a href=\"#sections\">back to top</a>] <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def decision_boundary(x_1):\n",
    "    \"\"\" Calculates the x_2 value for plotting the decision boundary.\"\"\"\n",
    "    return -x_1 + 1\n",
    "\n",
    "# Generate 100 random patterns for class1\n",
    "mu_vec1 = np.array([0,0])\n",
    "cov_mat1 = np.array([[1,0],[0,1]])\n",
    "x1_samples = np.random.multivariate_normal(mu_vec1, cov_mat1, 100)\n",
    "mu_vec1 = mu_vec1.reshape(1,2).T # to 1-col vector\n",
    "\n",
    "# Generate 100 random patterns for class2\n",
    "mu_vec2 = np.array([1,1])\n",
    "cov_mat2 = np.array([[1,0],[0,1]])\n",
    "x2_samples = np.random.multivariate_normal(mu_vec2, cov_mat2, 100)\n",
    "mu_vec2 = mu_vec2.reshape(1,2).T # to 1-col vector\n",
    "\n",
    "# Scatter plot\n",
    "f, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.scatter(x1_samples[:,0], x1_samples[:,1], marker='o', color='green', s=40, alpha=0.5)\n",
    "ax.scatter(x2_samples[:,0], x2_samples[:,1], marker='^', color='blue', s=40, alpha=0.5)\n",
    "plt.legend(['Class1 (w1)', 'Class2 (w2)'], loc='upper right') \n",
    "plt.title('Densities of 2 classes with 100 bivariate random patterns each')\n",
    "plt.ylabel('x2')\n",
    "plt.xlabel('x1')\n",
    "ftext = 'p(x|w1) ~ N(mu1=(0,0)^t, cov1=I)\\np(x|w2) ~ N(mu2=(1,1)^t, cov2=I)'\n",
    "plt.figtext(.15,.8, ftext, fontsize=11, ha='left')\n",
    "plt.ylim([-3,4])\n",
    "plt.xlim([-3,4])\n",
    "\n",
    "\n",
    "\n",
    "# Plot decision boundary\n",
    "x_1 = np.arange(-5, 5, 0.1)\n",
    "bound = decision_boundary(x_1)\n",
    "plt.annotate('R1', xy=(-2, 2), xytext=(-2, 2), size=20)\n",
    "plt.annotate('R2', xy=(2.5, 2.5), xytext=(2.5, 2.5), size=20)\n",
    "plt.plot(x_1, bound, color='r', alpha=0.8, linestyle=':', linewidth=3)\n",
    "\n",
    "x_vec = np.linspace(*ax.get_xlim())\n",
    "x_1 = np.arange(0, 100, 0.05)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"chern_err\"></a>\n",
    "<br></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Calculating the Chernoff theoretical bounds for P(error)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<a href=\"#sections\">back to top</a>] <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(error) \\le p^{\\beta}(\\omega_1) \\; p^{1-\\beta}(\\omega_2) \\; e^{-(\\beta(1-\\beta))}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Rightarrow 0.5^\\beta \\cdot 0.5^{(1-\\beta)} \\; e^{-(\\beta(1-\\beta))}$\n",
    "\n",
    "$\\Rightarrow 0.5 \\cdot e^{-\\beta(1-\\beta)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$min[P(\\omega_1), \\; P(\\omega_2)] \\le 0.5 \\; e^{-(\\beta(1-\\beta))} \\quad for \\; P(\\omega_1), \\; P(\\omega_2) \\ge \\; 0 \\; and \\; 0 \\; \\le \\; \\beta \\; \\le 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Chernoff Bound for $0 \\le \\beta \\le 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def chernoff_bound(beta):\n",
    "    return 0.5 * np.exp(-beta * (1-beta))\n",
    "\n",
    "betas = np.arange(0, 1, 0.01)\n",
    "c_bound = chernoff_bound(betas)\n",
    "\n",
    "plt.plot(betas, c_bound)\n",
    "plt.title('Chernoff Bound')\n",
    "plt.ylabel('P(error)')\n",
    "plt.xlabel('parameter beta')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the global minimum: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "x0 = [0.39] # initial guess (here: guessed based on the plot)\n",
    "res = minimize(chernoff_bound, x0, method='Nelder-Mead')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"emp_err\"></a>\n",
    "<br></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Calculating the empirical error rate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<a href=\"#sections\">back to top</a>] <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def decision_rule(x_vec):\n",
    "    \"\"\" Returns value for the decision rule of 2-d row vectors \"\"\"\n",
    "    x_1 = x_vec[0]\n",
    "    x_2 = x_vec[1]\n",
    "    return -x_1 - x_2 + 1\n",
    "\n",
    "w1_as_w2, w2_as_w1 = 0, 0\n",
    "\n",
    "for x in x1_samples:\n",
    "    if decision_rule(x) < 0:\n",
    "        w1_as_w2 += 1\n",
    "for x in x2_samples:\n",
    "    if decision_rule(x) > 0:\n",
    "        w2_as_w1 += 1\n",
    "\n",
    "emp_err = (w1_as_w2 + w2_as_w1) / float(len(x1_samples) + len(x2_samples))\n",
    "    \n",
    "print('Empirical Error: {}%'.format(emp_err * 100))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
