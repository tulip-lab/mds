{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Modern Data Science \n**(Module 05: Deep Learning)**\n\n---\n- Materials in this module include resources collected from various open-source online repositories.\n- You are free to use, change and distribute this package.\n\nPrepared by and for \n**Student Members** |\n2006-2018 [TULIP Lab](http://www.tulip.org.au), Australia\n\n---\n\n\n# Session E - Understanding Convolutions \n\nIn this lesson, we will learn more about the key concepts behind the CNNs (Convolutional Neural Networks from now on).\nThis lesson is not intended to be a reference for _machine learning, deep learning, convolutions or TensorFlow_. The intention is to give notions to the user about these fields. \n\n\n<font size = 3><strong>In this notebook we will overview the CNN</strong></font>\n<br>\n- <p><a href=\"#ref1\">Analogies</a></p>\n- <p><a href=\"#ref2\">Understanding and coding with Python</a></p>\n- <p><a href=\"#ref3\">Coding with TensorFlow</a></p>\n- <p><a href=\"#ref4\">Convolution applied on images</a></p>\n- <p><a href=\"#ref5\">Conclusion</a></p>\n<p></p>\n\n\n** References and additional reading and resources**\n* https://github.com/joanbruna/stat212b/blob/master/lec1.pdf\n* http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution\n* http://homepages.inf.ed.ac.uk/rbf/HIPR2/fourier.htm\n* This material is from [CognitiveClass.AI](https://cognitiveclass.ai), created by: <a href=\"https://ca.linkedin.com/in/rafaelblsilva\"> Rafael Belo Da Silva </a> \n* This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/).\n\n\n---\n\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"ref1\"></a>\n## 1. Analogies\n\nThere are several ways to understand Convolutional Layers without using a mathematical approach. We are going to explore some of the ideas proposed by the Machine Learning community.\n\n### 1.1 Instances of Neurons\n\nWhen you start to learn a programming language, one of the first phases of your development is the learning and application of functions. Instead of rewriting pieces of code everytime that you would, a good student is encouraged to code using functional programming, keeping the code organized, clear and concise.\nCNNs can be thought of as a simplification of what is really going on, a special kind of neural network which uses identical copies of the same neuron. These copies include the same parameters (shared weights and biases) and activation functions.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 1.2 Location and type of connections\n\nIn a fully connected layer NN, each neuron is connected to every neuron in the previous layer, and each connection has it's own weight. This is a totally general purpose connection pattern and makes no assumptions about the features in the input data thus not using any advantage that the knowledge of the data being used can bring. These types of layers are also very expensive in terms of memory and computation.\n\nIn contrast, in a convolutional layer each neuron is only connected to a few nearby local neurons in the previous layer, and the same set of weights is used to connect to them. For example, in the following image, the neurons in the h1 layer are connected only to some input units (pixels).\n      \n<img src=\"https://ibm.box.com/shared/static/mev168hepixnmc9zhh4hsr3t2ks3rpcc.png\" alt=\"HTML5 Icon\" style=\"width:500px;height:500px;\">\n<center> A figure presented in one of Lecun's papers. It shows the spatial relation and how the connections are modified until the output layer<a> [[ref]](http://help.sketchup.com/en) </a> </center> \n\n\n      \n \n\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 1.3 Feature Learning\n\nFeature engineering is the process of extracting useful patterns from input data that will help the prediction model to understand better the real nature of the problem. A good feature learning will present patterns in a way that increase significantly the accuracy and performance of the applied machine learning algorithms in a way that would be impossible or too expensive by the machine learning itself.\n\nFeature learning algorithms find the common patterns that are important to distinguish between the wanted classes and extract them automatically. After this process, they are ready to be used in a classification or regression problem. \n\nThe great advantage of CNNs is that they are uncommonly good at finding features in images that grow after each level, resulting in high-level features in the end. The final layers (can be one or more) use all these generated features for classification or regression. \n\nBasically, Convolutional Neural Networks are your best friend today to __automatically do Feature Engineering__ (Feature Learning) without wasting too much time creating your own codes and with no need of expertise in the field of Feature Engineering.\n\n<img src=\"https://ibm.box.com/shared/static/urzzkc7o5loqrlezcvn4kr594mxi9ftx.png\" alt=\"HTML5 Icon\" style=\"width:650px;height:250px;\">\n<center> Example of feature learning (automatically feature engineering), starting with simple features and ending with high-level features like human faces. <a> [[ref]](https://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-core-concepts/) </a> </center> \n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 1.4 Image Filter\n\n__How to create a convolved freature from an image ?__  \nThe image below is a 8x8 matrix of an image's pixels, converted to sing binary values in the next image(left), where 1 means a white pixel and 0 a black pixel. Later we will find out that typically this is a normalization, these values can actually have different scales. The most commmon usage is values between 0 and 255 for 8-bit grayscale images.  \n\n<img src=\"https://ibm.box.com/shared/static/0s5v7doe2p5xuzifs47bxmmuwrn3kra2.bmp\" alt=\"HTML5 Icon\" style=\"width:200px;height:200px;\">\n<center> An example of a low resolution image to be recognized. <a> [[ref]](http://help.sketchup.com/en) </a> </center> \n\nIn the below image, with an animation, you can see how the two-dimensional convolution operation would operate on the images. This operation is performed in most of the Deep Learning frameworks in their first phase. We need a sliding windows to create the convolved matrix:\n\n$\nkernel=\n\\begin{bmatrix}\n     1          & 0      & 1     \\\\\n     0          & 1    & 0     \\\\\n     1          & 0    & 1\n\\end{bmatrix}\n\\\\\n$ \n\n\n\n\nThe sliding window (a.k.a kernel, filter or feature detector) with a preset calculation ([[x1, x0,x1], [x0,x1,x0], [x1,x0,x1]]) goes through the image and creates a new matrix (feature map).", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": " <img src=\"https://ibm.box.com/shared/static/fvutcm8jwa5j2o7xv2zzqyz2yu3zwhz4.gif\" alt=\"HTML5 Icon\" style=\"width:450px;height:300px;\">\n<center>  Animations showing how a kernel interact with a matrix representing an image. <a> [[ref]](http://cs231n.github.io/convolutional-networks/) </a> </center>  \n \n \nIn the example above we used a 3\u00d73 filter (5x5 could also be used, but would be too complex). The values from the filter were multiplied element-wise with the original matrix (input image), then summed up. To get the full convolved matrix, the algorithm keep repeating this small procedure for each element by sliding the filter over the whole original matrix.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<img src=\"https://ibm.box.com/shared/static/7maczejdeej0qoz3pzkysw0y8qb70g2h.png\" alt=\"HTML5 Icon\" style=\"width:500px;height:200px;\"> \n<center>  Illustration of the operation for one position of the kernel. <a> [[ref]](http://colah.github.io/posts/2014-07-Understanding-Convolutions/) </a> </center>\n\nJust like the referenced example, we can think of a one-dimensional convolution as sliding function (1x1 or 1x2 filter) multiplying and adding on top of an array (1 dimensional array, instead of the original matrix).  \n \n__What is the output of applying a kernel on an image?__   \nThe famous GIMP (Open Source Image Editor) has an explanation about the convolution operation applied to images that can help us understand how Neural Networks will interact with this tool.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<img src=\"https://ibm.box.com/shared/static/wixvbo9pk0f6r6ln879ah9jjo0ua0fo5.png\" alt=\"HTML5 Icon\" style=\"width:700px;height:350px;\"> \n<center>   Applying the left kernel to the image will result into a blurr effect.<a> [[ref]](http://colah.github.io/posts/2014-07-Understanding-Convolutions/) </a> </center>\n\n\nWell, this is very good if you want nice effects for your social media photos, but in the field of computer vision you need detailed patterns (remember feature learning) that are almost erased using a kernel like that. A more suitable example would be the Kernel/filter that shows edges from photos (the first recognizable feature of an image).\n\n\n__Lets try another kernel: __  \nTaking the values \u22121 and 1 on two adjacent pixels and zero everywhere else for the kernel, result in the following image. That is, we subtract two adjacent pixels. When side by side pixels are similar, this gives us approximately zero. On edges, however, adjacent pixels are very different in the direction perpendicular to the edge. Knowing that results distant from zero will result in brighter pixels, you can already guess the result of this type of kernel.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<img src=\"https://ibm.box.com/shared/static/z673yijcsfqs5rd8auc1dwmtkejyizv0.png\" alt=\"HTML5 Icon\" style=\"width:700px;height:350px;\">\n<center> Applying the new left kernel to the image will result into a edge detection, this output is normallly useful for the initial layers of a CNN.<a> [[ref]](http://colah.github.io/posts/2014-07-Understanding-Convolutions/) </a> </center>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "***\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"ref2\"></a>\n## 2. Understanding and coding with Python", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 2.1 Convolution: 1D operation with Python (Numpy/Scipy)", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "### Mathematical notation\nIn this first example, we will use the pure mathematical notation. Here we have a one dimensional convolution operation. Lets say h is our image and x is our kernel: \n  \nx[i] = { 3, 4, 5 }  \nh[i] = { 2, 1, 0 }  \n\nwhere i = index\n\nTo use the convolution operation between the two arrays try the code below to see how it's easy to do in Python.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import numpy as np\n\nh = [2,1,0]\nx = [3,4,5]\n \n\ny = np.convolve(x,h)\ny  "
        }, 
        {
            "source": "sliding x window over h:   \n- 6  = 2\\*3  \n- 11 = 1\\*3 + 2\\*4  \n- 14 = 0\\*3 + 1\\*4 + 2\\*5  \n- 5  = 0\\*4 + 1\\*5  \n- 0  = 0\\*5", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#### Now we are going to verify what Python did, because we don't trust computer outputs while we are learning. Using the equation of convolution for y[n]: \n  \n$$y[n] = \\sum x[k] \\cdot h[n-k] $$\n\n\nAnd then, executing manually the computation:\n\n$ \ny[0]= \\sum\\limits_{k\\to\\infty}^\\infty x[k]\\cdot h[0-k]= x[0]\\cdot h[0]=3\\cdot 2=6 \\\\\ny[1]= \\sum\\limits_{k\\to\\infty}^\\infty x[k]\\cdot h[1-k]= x[0]\\cdot h[1-0]+x[1]\\cdot h[1-1] + \\space... \\\\ \n\\qquad\\qquad\\qquad\\qquad\\qquad   = x[0]\\cdot h[1] + x[1]\\cdot h[0]= 3\\cdot1+4\\cdot 2=11 \\\\\ny[2]= \\sum\\limits_{k\\to\\infty}^\\infty x[k]\\cdot h[2-k]= x[0]\\cdot h[2-0]+x[1]\\cdot h[2-1]+x[2]\\cdot h[2-2]+ \\space ... \\\\ \n\\qquad\\qquad\\qquad\\qquad\\qquad   = x[0]\\cdot h[2] + x[1]\\cdot h[1]+x[2]\\cdot h[0]= 3\\cdot0+4\\cdot 1 +5\\cdot 2=14 \\\\\ny[3]= \\sum\\limits_{k\\to\\infty}^\\infty x[k]\\cdot h[3-k]= x[0]\\cdot h[3-0]+x[1]\\cdot h[3-1]+x[2]\\cdot h[3-2]+ x[3]\\cdot h[3-3] + \\space... \\\\ \n\\qquad\\qquad\\qquad\\qquad\\qquad   = x[0]\\cdot h[3] +x[1]\\cdot h[2]\\cdot + x[2]\\cdot h[1]+x[3]\\cdot h[0]=0+0+5 \\cdot 1 +0=5 \\\\\ny[4]= \\sum\\limits_{k\\to\\infty}^\\infty x[k]\\cdot h[4-k]= x[0]\\cdot h[4-0]+x[1]\\cdot h[4-1]+x[2]\\cdot h[4-2]+\\space... =0\\\\ \n$", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "print(\"Compare with the following values from Python: y[0] = {0} ; y[1] = {1}; y[2] = {2}; y[3] = {3}; y[4] = {4}\".format(y[0],y[1],y[2],y[3],y[4])) "
        }, 
        {
            "source": "There are three methods to apply kernel on the matrix, __with padding (full)__, __with padding(same)__ and __without padding(valid)__:  \n\n### 1) Visually understanding the operation with padding (full)\n\nLets think of the kernel as a sliding window. We have to come with the solution of padding zeros on the input array. Ths is a very famous implementation and will be easier to show how it works with a simple example, consider this case:\n  \nx[i] = [6,2]  \nh[i] = [1,2,5,4]  ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Using the zero padding, we can calculate the convolution.\n \nYou have to invert the filter x, otherwise the operation would be cross-correlation.\nFirst step, (now with zero padding): ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "[2  6]\n |  |\n V  V\n 0 [1 2 5 4]", 
            "cell_type": "raw", 
            "metadata": {}
        }, 
        {
            "source": "= 2 \\* 0 + 6 * 1 = 6 \n \nSecond step:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "  [2  6]  \n   |  |  \n   V  V  \n0 [1  2  5  4]  ", 
            "cell_type": "raw", 
            "metadata": {}
        }, 
        {
            "source": "= 2 \\* 1 + 6 * 2 = 14 (the arrows represent the connection between the kernel and the input)\n\nThird step:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "     [2  6]  \n      |  |  \n      V  V  \n0 [1  2  5  4]  ", 
            "cell_type": "raw", 
            "metadata": {}
        }, 
        {
            "source": "= 2 \\* 2 + 6 * 5 = 34  \n  \nFourth step:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "        [2  6]\n         |  |\n         V  V\n0 [1  2  5  4]  ", 
            "cell_type": "raw", 
            "metadata": {}
        }, 
        {
            "source": "= 2 \\* 5 + 6 * 4 = 34\n\nFifth step:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "           [2  6]\n            |  |\n            V  V\n0 [1  2  5  4] 0  ", 
            "cell_type": "raw", 
            "metadata": {}
        }, 
        {
            "source": "= 2 \\* 4 + 6 * 0 = 8\n \nThe result of the convolution for this case, listing all the steps, would then be: Y = [6 14 34 34 8]\n\nBelow we verify with numpy:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import numpy as np\n\nx= [6,2]\nh= [1,2,5,4]\n\ny= np.convolve(x,h,\"full\")  #now, because of the zero padding, the final dimension of the array is bigger\ny  "
        }, 
        {
            "source": "### 2) Visually understanding the operation with \"same\"\nIn this approach, we just add the zero to left (and top of the matrix in 2D). That is, only the first 4 steps of \"full\" method:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import numpy as np\n\nx= [6,2]\nh= [1,2,5,4]\n\ny= np.convolve(x,h,\"same\")  #it is same as zero padding, but withgenerates same \ny  "
        }, 
        {
            "source": "### 3) Visually understanding the operation with no padding (valid)\n\nIn the last case we only applied the kernel when we had a compatible position on the h array, in some cases you want a dimensionality reduction. For this purpose, we simple ignore the steps tha would need padding:\n    \nx[i] = [6 2] \nh[i] = [1 2 5 4]\n\nYou have to invert the filter x, otherwise the operation would be cross-correlation.\nFirst step, (now without zero padding):", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "[2  6]  \n |  |  \n V  V  \n[1  2  5  4]  ", 
            "cell_type": "raw", 
            "metadata": {}
        }, 
        {
            "source": "= 2 \\* 1 + 6 * 2 = 14 (the arrows represent the connection between the kernel and the input)\n\nSecond step: ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "   [2  6]  \n    |  |   \n    V  V  \n[1  2  5  4]  ", 
            "cell_type": "raw", 
            "metadata": {}
        }, 
        {
            "source": "= 2 \\* 2 + 6 * 5 = 34  \n  \nThird step:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "      [2  6]\n       |  |\n       V  V\n[1  2  5  4]  ", 
            "cell_type": "raw", 
            "metadata": {}
        }, 
        {
            "source": "= 2 \\* 5 + 6 * 4 = 34\n\nThe result of the convolution for this mode would then be Y= [14 34 34] = [ First, second, third step]", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Let's verify with numpy", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import numpy as np\n\nx= [6,2]\nh= [1,2,5,4]\n\ny= np.convolve(x,h,\"valid\")  #we will understand why we used the argument valid in the next example\ny  "
        }, 
        {
            "source": "### 2.2 Convolution: 2D operation with Python (Numpy/Scipy)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "The 2D convolution operation is defined as:\n\n<font size=\"4\">$$ I'= \\sum\\limits_{u,v} I(x-u,y-v)g(u,v) $$ </font> \n \n \nBelow we will apply the equation to an image represented by a 3x3 matrix according to the function g = (-1 1). Please note that when we apply the kernel we always use its inversion. \n \n$\nI=\n\\begin{bmatrix}\n     255          & 7      & 3     \\\\\n     212          & 240    & 4     \\\\\n     218          & 216    & 230\n\\end{bmatrix}\n\\\\\n$ \n\n$\ng=\n\\begin{bmatrix}\n     -1          & 1      \n\\end{bmatrix}\n\\\\\n$ \n  \n$\n\\begin{bmatrix}\n    \\textbf{1}\\cdot \\textbf{0}      & \\textbf{-1} \\ast \\textbf{255}  & 7      & 3     \\\\\n    0              & 212          & 240    & 4     \\\\\n    0              & 218          & 216    & 230\n\\end{bmatrix}\n\\rightarrow\n\\begin{bmatrix}\n    \\textbf{-255}  & 7      & 3     \\\\\n    212            & 240    & 4     \\\\\n    218            & 216    & 230\n\\end{bmatrix}\n\\\\\n$\n\n$\n\\begin{bmatrix}\n    \\textbf{1}\\ast \\textbf{255}      & \\textbf{-1} \\ast \\textbf{7}  & 3    \\\\\n    212          & 240    & 4     \\\\\n    218          & 216    & 230\n\\end{bmatrix}\n\\rightarrow\n\\begin{bmatrix}\n    -255           & \\textbf{248}      & 3     \\\\\n    212            & 240    & 4     \\\\\n    218            & 216    & 230\n\\end{bmatrix}\n\\\\\n$\n\n$\n\\begin{bmatrix}\n    255          & \\textbf{1}\\ast\\textbf{7}  & \\textbf{-1}\\ast\\textbf{3}    \\\\\n    212          & 240    & 4     \\\\\n    218          & 216    & 230\n\\end{bmatrix}\n\\rightarrow\n\\begin{bmatrix}\n    -255           & 248      & \\textbf{4}     \\\\\n    212            & 240      & 4     \\\\\n    218            & 216      & 230\n\\end{bmatrix}\n\\\\\n$\n\n  \n$\n\\begin{bmatrix}\n    0              & 255          & 7          & 3     \\\\\n    \\textbf{1}\\ast \\textbf{0}    & \\textbf{-1} \\ast \\textbf{212}  & 240     & 4     \\\\\n    0              & 218          & 216    & 230\n\\end{bmatrix}\n\\rightarrow\n\\begin{bmatrix}\n    \\textbf{-255}  & 248    & 4     \\\\\n    -212            & 240    & 4     \\\\\n    218            & 216    & 230\n\\end{bmatrix}\n\\\\\n$\n \n \n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "We don't have to finish the calculations, we have the computer at our side. So, let's see what is the code to proceede with this operation: ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "from scipy import signal as sg\n\nI= [[255,   7,  3],\n    [212, 240,  4],\n    [218, 216, 230],]\n\ng= [[-1,1]]\n\nprint ('Without zero padding \\n')\nprint ('{0} \\n'.format(sg.convolve( I, g, 'valid')))\n# The 'valid' argument states that the output consists only of those elements \n# that do not rely on the zero-padding.\n\nprint ('With zero padding \\n')\nprint sg.convolve( I, g)"
        }, 
        {
            "source": "For a more difficult case where h= [ [-1  1] , [2   3] ]\n\n$\n\\begin{bmatrix}\n    \\textbf{3}\\ast \\textbf{0}      & \\textbf{2} \\ast \\textbf{0}     & 0      & 0     \\\\\n    \\textbf{1}\\ast \\textbf{0}      & \\textbf{-1} \\ast \\textbf{255}  & 7      & 3     \\\\\n    0              & 212          & 240    & 4     \\\\\n    0              & 218          & 216    & 230\n\\end{bmatrix}\n\\rightarrow\n\\begin{bmatrix}\n    \\textbf{-255}  & 7      & 3     \\\\\n    212            & 240    & 4     \\\\\n    218            & 216    & 230\n\\end{bmatrix}\n\\\\\n$", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "from scipy import signal as sg\n\nI= [[255,   7,  3],\n    [212, 240,  4],\n    [218, 216, 230],]\n\ng= [[-1,  1],\n    [ 2,  3],]\n\nprint ('With zero padding \\n')\nprint ('{0} \\n'.format(sg.convolve( I, g, 'full')))\n# The output is the full discrete linear convolution of the inputs. \n# It will use zero to complete the input matrix\n\nprint ('With zero padding_same_ \\n')\nprint ('{0} \\n'.format(sg.convolve( I, g, 'same')))\n# The output is the full discrete linear convolution of the inputs. \n# It will use zero to complete the input matrix\n\n\nprint ('Without zero padding \\n')\nprint (sg.convolve( I, g, 'valid'))\n# The 'valid' argument states that the output consists only of those elements \n#that do not rely on the zero-padding."
        }, 
        {
            "source": "----------------", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"ref3\"></a>\n## 3. Coding with TensorFlow", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "Numpy is great because it has high optmized matrix operations implemented in a backend using C/C++. However, if our goal is to work with DeepLearning, we need much more. TensorFlow does the same work, but instead of returning to Python everytime, it creates all the operations in the form of graphs and execute them once with the highly optimized backend.\n\nSuppose that you have two tensors:\n\n* 3x3 filter (4D tensor = [3,3,1,1] = [width, height, channels, number of filters])\n* 10x10 image (4D tensor = [1,10,10,1] = [batch size, width, height, number of channels]\n\nThe output size for zero padding 'SAME' mode will be:  \n* the same as input = 10x10  \n\nThe output size without zero padding 'VALID' mode:  \n* input size - kernel dimension +1 = 10 -3 + 1 = 8 = 8x8 ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import tensorflow as tf\n\n#Building graph\n\ninput = tf.Variable(tf.random_normal([1,10,10,1]))\nfilter = tf.Variable(tf.random_normal([3,3,1,1]))\nop = tf.nn.conv2d(input, filter, strides=[1, 1, 1, 1], padding='VALID')\nop2 = tf.nn.conv2d(input, filter, strides=[1, 1, 1, 1], padding='SAME')\n\n#Initialization and session\ninit = tf.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init)\n\n    print(\"Input \\n\")\n    print('{0} \\n'.format(input.eval()))\n    print(\"Filter/Kernel \\n\")\n    print('{0} \\n'.format(filter.eval()))\n    print(\"Result/Feature Map with valid positions \\n\")\n    result = sess.run(op)\n    print(result)\n    print('\\n')\n    print(\"Result/Feature Map with padding \\n\")\n    result2 = sess.run(op2)\n    print(result2)"
        }, 
        {
            "source": "----------------", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"ref4\"></a>\n## 4. Convolution applied on images", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Upload your own image (drag and drop to this window) and type its name on the input field on the next cell (press _shift + enter_). The result of this pre-processing will be an image with only a greyscale channel.\n\nYou can type _bird.jpg_ to use a default image", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import wget\n\nlink_to_data = 'https://raw.githubusercontent.com/tuliplab/mds/master/Jupyter/image/bird.jpg'\nDataSet = wget.download(link_to_data)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!ls -l *.jpg"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "source": "\n#Importing\nimport numpy as np\nfrom scipy import signal\nfrom scipy import misc\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\n\n### Load image of your choice on the notebook\nprint(\"Please type the name of your test image after uploading to \\\nyour notebook (just drag and grop for upload. Please remember to \\\ntype the extension of the file. Default: bird.jpg\")\n\nraw= raw_input()\n\nim = Image.open(raw)  # type here your image's name\n\n# uses the ITU-R 601-2 Luma transform (there are several \n# ways to convert an image to grey scale)\n\nimage_gr = im.convert(\"L\")    \nprint(\"\\n Original type: %r \\n\\n\" % image_gr)\n\n# convert image to a matrix with values from 0 to 255 (uint8) \narr = np.asarray(image_gr) \nprint(\"After conversion to numerical representation: \\n\\n %r\" % arr) \n### Activating matplotlib for Ipython\n%matplotlib inline\n\n### Plot image\n\nimgplot = plt.imshow(arr)\nimgplot.set_cmap('gray')  #you can experiment different colormaps (Greys,winter,autumn)\nprint(\"\\n Input image converted to gray scale: \\n\")\nplt.show(imgplot)"
        }, 
        {
            "source": "Now, we will experiment using an edge detector kernel.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "kernel = np.array([\n                        [ 0, 1, 0],\n                        [ 1,-4, 1],\n                        [ 0, 1, 0],\n                                     ]) \n\ngrad = signal.convolve2d(arr, kernel, mode='same', boundary='symm')"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "%matplotlib inline\n\nprint('GRADIENT MAGNITUDE - Feature map')\n\nfig, aux = plt.subplots(figsize=(10, 10))\naux.imshow(np.absolute(grad), cmap='gray')\n"
        }, 
        {
            "source": "If we change the kernel and start to analyse the outputs we would be acting as a CNN. The difference is that a Neural Network do all this work automatically (the kernel adjustment using different weights). In addition, we can understand how biases affect the behaviour of feature maps", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "_Please note that when you are dealing with most of the real applications of CNNs, you usually convert the pixels values to a range from 0 to 1. This process is called normalization._", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "type(grad)\n\ngrad_biases = np.absolute(grad) + 100\n\ngrad_biases[grad_biases > 255] = 255\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "%matplotlib inline\n\nprint('GRADIENT MAGNITUDE - Feature map')\n\nfig, aux = plt.subplots(figsize=(10, 10))\naux.imshow(np.absolute(grad_biases), cmap='gray')"
        }, 
        {
            "source": "<a id=\"ref5\"></a>\n## 5. Exercise\n\nThis understanding of how convolutions work are the foundation of how Convolutional Neural Networks work. After this tuorial you are supposed to understand the underlying mathematical concepts and how to apply them using| Python (numpy) and Tensorflow. The next setp is to extrapolate this knowledge to Machine Learning applications.\n\nThis exercise is about learning to apply convolutions on an image using Tensorflow. Idea is to create a weight matrix and apply the function conv2d with 'same' and 'Valid' padding to check the effects on output image. \n\nTo give an overview of how the output changes based on convolution parameters, this exercise is designed to build Layer one of Convolution Neural Network (CNN) along with maxpooling and relu functions and Visualize the outputs given an input image. \n\n### First, let's import the TensorFlow library and Python dependencies", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#Importing\nimport numpy as np\nfrom scipy import signal\nfrom scipy import misc\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nimport tensorflow as tf"
        }, 
        {
            "source": "### Read and display image by coverting it to a gray scale.   \n\nRead the input image as float data type as Tensorflow accepts images in float format. \n\nFirst download a samole image:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import wget\n\nlink_to_data = 'https://github.com/tuliplab/mds/blob/master/Jupyter/image/lena.png'\nDataSet = wget.download(link_to_data)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!ls -l *.png"
        }, 
        {
            "source": "####  Run this Cell to experiment with Lena Image.  RGB with Size (512, 512)\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#read the image as Float data type\nim=misc.imread(\"lena.png\").astype(np.float)\n\n#im=misc.imread(\"one.png\").astype(np.float)\n\n#Convert image to gray scale\ngrayim=np.dot(im[...,:3], [0.299, 0.587, 0.114])\n\n\n#Plot the images\n%matplotlib inline\n\nplt.subplot(1, 2, 1)\nplt.imshow(im)\nplt.xlabel(\" Float Image \")\n\nplt.subplot(1, 2, 2)\nplt.imshow(grayim, cmap=plt.get_cmap(\"gray\"))\nplt.xlabel(\" Gray Scale Image \")\n\n"
        }, 
        {
            "source": "#### Run this cell to experiemnt with MNIST image of Number 1. Gray Scale SIze (28, 28)\n\n\nPrint the shape of Gray Scale Image", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Your Code Goes Here\n\n\n"
        }, 
        {
            "source": "<div align=\"right\">\n<a href=\"#printgray\" class=\"btn btn-default\" data-toggle=\"collapse\">Click here for the solution</a>\n</div>\n<div id=\"printgray\" class=\"collapse\">\n```\nprint grayim.shape\n\n```\n</div>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Extend the Dimensions of the Gray Scale Image\n\nFor convolution, TensorFlow accepts Images of dimensions:\n\n[num of images, width, height, channels].\n\nIn this case we are looking for dimensions of [1,512,512,1] from (512,512).", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "Image = np.expand_dims(np.expand_dims(grayim, 0), -1)\n\nprint Image.shape\n\n"
        }, 
        {
            "source": "### Create Place holder for an input image and Print the Shape\n\nThe placeholder takes input in float format and same size of input image", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Your Code Goes Here\n\n\n"
        }, 
        {
            "source": "<div align=\"right\">\n<a href=\"#placeholder\" class=\"btn btn-default\" data-toggle=\"collapse\">Click here for the solution</a>\n</div>\n<div id=\"placeholder\" class=\"collapse\">\n```\nimg= tf.placeholder(tf.float32, [None,512,512,1])\nprint img.get_shape().as_list()\n\n```\n</div>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Create a Variable for Weight Matrix and Print the Shape\n\nThe shape of weight matrix is of the form:\n[ Height, widht, Input , Output]. \n\nIn this case lets create weight matrix of size 5 X 5 and keeping number of inputs and output to just 1. So, the shape is of form [5,5,1,1].", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Your Code Goes Here\n\n"
        }, 
        {
            "source": "<div align=\"right\">\n<a href=\"#placeA\" class=\"btn btn-default\" data-toggle=\"collapse\">Click here for the solution</a>\n</div>\n<div id=\"placeA\" class=\"collapse\">\n```\nshape=[5,5,1,1]\nweights =tf.Variable(tf.truncated_normal(shape, stddev=0.05))\nprint weights.get_shape().as_list()\n```\n</div>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "###  Create Two Convolution Graphs in Tensorflow\n\nlets use the functon tf.nn.conv2d to create a graph for convolution operation with padding 'same' and Padding 'Valid'.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# You Code Goes Here\n\n# for convolution output 1\nConOut=\n\n# for convolution output 2\nConOut2= \n\n\n\n"
        }, 
        {
            "source": "<div align=\"right\">\n<a href=\"#Graph\" class=\"btn btn-default\" data-toggle=\"collapse\">Click here for the solution</a>\n</div>\n<div id=\"Graph\" class=\"collapse\">\n```\nConOut = tf.nn.conv2d(input=img,\n                         filter=weights,\n                         strides=[1, 1, 1, 1],\n                         padding='SAME')\n\nConOut2 = tf.nn.conv2d(input=img,\n                         filter=weights,\n                         strides=[1, 1, 1, 1],\n                         padding='VALID')\n```\n</div>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Initialize all variables and Run the Sessions", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "init = tf.global_variables_initializer()\nsess= tf.Session()\nsess.run(init)"
        }, 
        {
            "source": "Run the sesions to get the results for two convolution operations ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Your Code Goes Here\n\n# Session for Result 1\nresult = \n\n\n# Session for Result 2\nresult2 = \n\n"
        }, 
        {
            "source": "<div align=\"right\">\n<a href=\"#Result\" class=\"btn btn-default\" data-toggle=\"collapse\">Click here for the solution</a>\n</div>\n<div id=\"Result\" class=\"collapse\">\n```\nresult = sess.run(ConOut,feed_dict={img:Image})\n\nresult2 = sess.run(ConOut2,feed_dict={img:Image})\n```\n</div>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "###  Display the output images \n\nThe result of convolution with 'same' padding is of the form [1,512,512,1] and for 'valid' padding image is of the shape [1,508,508,1]. To display the images, our job is to reshape the dimensions in the form (512,512) and (508,508) respectively.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "\n# for the result with 'SAME' Padding \n\n#reduce the dimension\nvec = np.reshape(result, (1, -1));\n# Reshape the image\nimage= np.reshape(vec,(512,512))\n\nprint image.shape\n\n\n# for the result with 'VALID' Padding \n\n#reduce the dimension\nvec2 = np.reshape(result2, (1, -1));\n# Reshape the image\nimage2= np.reshape(vec2,(508,508))\n\nprint image2.shape"
        }, 
        {
            "source": "Display the images ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#Plot the images\n%matplotlib inline\n\nplt.subplot(1, 2, 1)\nplt.imshow(image,cmap=plt.get_cmap(\"gray\"))\nplt.xlabel(\" SAME Padding \")\n\nplt.subplot(1, 2, 2)\nplt.imshow(image2, cmap=plt.get_cmap(\"gray\"))\nplt.xlabel(\" VALID Padding \")"
        }, 
        {
            "source": "Feel free to change the weight matrix and experiment with different Paddings to see the changes in output images. \n\n#### Create First Convolution Neural Network Layer\n\n\nusing above conv2d function lets build our first conv Layer. Usually most general CNN architecture Layer 1 comprises of Convolution, Relu and MaxPooling. Lets create these functions to check the effects on \"Lena\" Image. Depending on the architecture these functions may change. For this exercise lets assume our Layer 1 has just three functions Convolution, Relu and Maxpooling.\n\nIt is most often repetation of these layers stacked on top of each other to create Deep CNN\n\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#lets create functions for convolution and Maxpooling\n\ndef conv2d (X,W):\n    \n    #Your Code Goes Here\n    \n \n\ndef MaxPool (X):\n    \n    #Your Code Goes Here\n\n"
        }, 
        {
            "source": "<div align=\"right\">\n<a href=\"#Function\" class=\"btn btn-default\" data-toggle=\"collapse\">Click here for the solution</a>\n</div>\n<div id=\"Function\" class=\"collapse\">\n```\nreturn tf.nn.conv2d(input=X,filter=W,strides=[1, 1, 1, 1],padding='SAME')\n\nreturn tf.nn.max_pool(X, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n```\n</div>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#### Create Weights and Biases for Convolution\n\nThe weights are of the shape [Height, Width , Input , Output]. Here lets create the weights of size 5X5 which has 1 input and 32 Outputs. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "\nweights = {\n        # 5 x 5 convolution, 1 input image, 32 outputs\n       \n        \n       \n    }\n\nbiases = {\n        #bias should be of the size of number of Outputs\n       \n        \n    }\n     \n    "
        }, 
        {
            "source": "<div align=\"right\">\n<a href=\"#Weights\" class=\"btn btn-default\" data-toggle=\"collapse\">Click here for the solution</a>\n</div>\n<div id=\"Weights\" class=\"collapse\">\n```\n 'W_conv1': tf.Variable(tf.random_normal([5, 5, 1, 32]))\n\n 'b_conv1': tf.Variable(tf.random_normal([32]))\n```\n</div>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Define a TensorFlow Graph for Relu, Convolution and Maxpooling\n\nThe output of Conv2d is passed through Relu Layer and finally, the output of Relu is given as input for Maxpooling layer. Let's define the graph and print the shapes.The size of Image is reduced after passing through Maxpool Layer. You can change the size and strides in Maxpool layer to check how the image size varies \n\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "\nconv1 = # Your Code Goes here\n\nMxpool = # Your Code Goes here\n\n    \nprint conv1.get_shape().as_list()\n\nprint Mxpool.get_shape().as_list()"
        }, 
        {
            "source": "<div align=\"right\">\n<a href=\"#Conv\" class=\"btn btn-default\" data-toggle=\"collapse\">Click here for the solution</a>\n</div>\n<div id=\"Conv\" class=\"collapse\">\n```\ntf.nn.relu(conv2d(img, weights['W_conv1']) + biases['b_conv1'])\n\nMaxPool (conv1)\n```\n</div>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#### Initialize all TensorFlow Variables and Run the Session", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "\ninit = tf.global_variables_initializer()\nsess= tf.Session()\nsess.run(init)"
        }, 
        {
            "source": "#### Run session to get the output of Layer 1 \n\nThe session is run on MxPool which will be the final output ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "Layer1 = # Your Code Goes Here"
        }, 
        {
            "source": "<div align=\"right\">\n<a href=\"#Result123\" class=\"btn btn-default\" data-toggle=\"collapse\">Click here for the solution</a>\n</div>\n<div id=\"Result123\" class=\"collapse\">\n```\nsess.run(Mxpool,feed_dict={img:Image})\n\n\n```\n</div>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#### Visualize the Output of Convolution layer1 ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "print Layer1.shape\n\nvec = np.reshape(Layer1, (256,256,32));\nprint vec.shape\n\nfor i in range (32):\n    \n    image=vec[:,:,i]\n    #print image\n    #image *= 255.0/image.max() \n    #print image\n    plt.imshow(image,cmap=plt.get_cmap(\"gray\"))\n    plt.xlabel( i , fontsize=20, color='red')\n    plt.show()\n    plt.close()\n\n"
        }, 
        {
            "source": "Please feel free to experiemnt with different values of: Padding, Kernel Size to see how the output varies\n\nThe Idea behind this exercise is to gain understanding on how to apply convolutions and other functions on Images. We are NOT training Neural Network here, however just checking the effects of changing parameters of the above functions which are basic building blocks of any Deep Convolution neural Networks.  ", 
            "cell_type": "markdown", 
            "metadata": {}
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2 with Spark 1.6 (Unsupported)", 
            "name": "python2", 
            "language": "python"
        }, 
        "widgets": {
            "state": {}, 
            "version": "1.1.2"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "2.7.11", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython2", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }
        }, 
        "anaconda-cloud": {}
    }, 
    "nbformat": 4
}